MACHINE LEARNING
ASSIGNMENT - 6
In Q1 to Q5, only one option is correct, Choose the correct option:
1. In which of the following you can say that the model is overfitting?
A) High R-squared value for train-set and High R-squared value for test-set.
B) Low R-squared value for train-set and High R-squared value for test-set.
C) High R-squared value for train-set and Low R-squared value for test-set.(Answer is C)
D) None of the above

2. Which among the following is a disadvantage of decision trees?
A) Decision trees are prone to outliers.
B) Decision trees are highly prone to overfitting.(The Answer is B)
C) Decision trees are not easy to interpret
D) None of the above.

3. Which of the following is an ensemble technique?
A) SVM B) Logistic Regression
C) Random Forest D) Decision tree(The Answer is C)

4. Suppose you are building a classification model for detection of a fatal disease where detection of 
the disease is most important. In this case which of the following metrics you would focus on?
A) Accuracy B) Sensitivity(The Answer is B)
C) Precision D) None of the above.

5. The value of AUC (Area under Curve) value for ROC curve of model A is 0.70 and of model B is 
0.85. Which of these two models is doing better job in classification?
A) Model A B) Model B
C) both are performing equal D) Data Insufficient(The Answer is B)

In Q6 to Q9, more than one options are correct, Choose all the correct options:
6. Which of the following are the regularization technique in Linear Regression?? 
A) Ridge B) R-squared
 C) MSE D) Lasso(The Answer is A and D)

7. Which of the following is not an example of boosting technique?
 A) Adaboost B) Decision Tree(The Answer is B)
C) Random Forest D) Xgboost.

8. Which of the techniques are used for regularization of Decision Trees? 
A) Pruning B) L2 regularization
C) Restricting the max depth of the tree D) All of the above(The Answer is A)

9. Which of the following statements is true regarding the Adaboost technique?
A) We initialize the probabilities of the distribution as 1/n, where n is the number of data-points
B) A tree in the ensemble focuses more on the data points on which the previous tree was not 
performing well
C) It is example of bagging technique
D) None of the above(The Answer is B)

Q10 to Q15 are subjective answer type questions, Answer them briefly.
10. Explain how does the adjusted R-squared penalize the presence of unnecessary predictors in the
model?
Every time you add a independent variable to a model, the R-squared increases, even if the independent variable is insignificant. It never declines. Whereas Adjusted R-squared increases only when independent variable is significant and affects dependent variable.

11. Differentiate between Ridge and Lasso Regression.
Similar to the lasso regression, ridge regression puts a similar constraint on the coefficients by introducing a penalty factor. However, while lasso regression takes the magnitude of the coefficients, ridge regression takes the square. Ridge regression is also referred to as L2 Regularization

12. What is VIF? What is the suitable value of a VIF for a feature to be included in a regression 
modelling?
Variance inflation factor (VIF) is a measure of the amount of multicollinearity in a set of multiple regression variables
The default VIF cutoff value is 5; only variables with a VIF less than 5 will be included in the model. However, note that many sources say that a VIF of less than 10 is acceptable.

13. Why do we need to scale the data before feeding it to the train the model?
To ensure that the gradient descent moves smoothly towards the minima and that the steps for gradient descent are updated at the same rate for all the features

 
MACHINE LEARNING
ASSIGNMENT - 6
14. What are the different metrics which are used to check the goodness of fit in linear regression?

Mean Square Error(MSE)/Root Mean Square Error(RMSE)

While R Square is a relative measure of how well the model fits dependent variables, Mean Square Error is an absolute measure of the goodness for the fit

15. From the following confusion matrix calculate sensitivity, specificity, precision, recall and accuracy.
Actual/Predicted   True   False
True               1000    50
False              250     120

sensitivity or recall = TP/TP+FN = 0.8

specificity = TN / TN + FP = 0.70

precision = TP / TP + FP = 0.95

accuracy = TP + TN / TP + TN + FP + FN = 0.79